{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit"
    },
    "interpreter": {
      "hash": "cb780d572e831aa1c7a964aa13cce9a81c201b20bea2761400e5c772d1b04f6b"
    },
    "colab": {
      "name": "statistical_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lWhM2vwVucoT",
        "0DdGJqIGk7Q1",
        "1RSR72-mfd1G",
        "0VNTdnCElMS3",
        "abSy0PLGlUVI",
        "OV_dJWtplk8S",
        "GX1UFbIQlEvk",
        "zAEAJMiYoQPE",
        "Uu43P7cIobzG",
        "28Fmcm7wpW3U",
        "8NBV0GAdyEty",
        "oglO1rwJyJ2A",
        "rQQ16w6j6_4a",
        "rWQVtpQikiLB"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "lWhM2vwVucoT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# import models\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.linear_model import Lasso\r\n",
        "from sklearn.preprocessing import PolynomialFeatures\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.linear_model import RidgeClassifier\r\n",
        "from sklearn import neighbors\r\n",
        "from sklearn import svm\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "# import other libraries\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "import csv"
      ],
      "outputs": [],
      "metadata": {
        "id": "sj98TdfTkzID"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# load data\r\n",
        "X = np.load('data/samples.npy')\r\n",
        "y = np.load('data/labels.npy')"
      ],
      "outputs": [],
      "metadata": {
        "id": "-GH6_POV7iTC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# create csv\r\n",
        "OUTPUT_FILE = \"data/grid_search/grid_search_results.csv\""
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "## Hyperparameter grid\r\n",
        "criterion = ['gini', 'entropy']\r\n",
        "max_depth = [3, 4, 5]\r\n",
        "max_features = [55, 56]\r\n",
        "max_leaf_nodes = list(range(2, 30))\r\n",
        "min_impurity_decrease = [0, 0.1]\r\n",
        "min_samples_leaf = [2, 3]\r\n",
        "\r\n",
        "hyperparameters = [criterion, max_depth, max_features, max_leaf_nodes, min_impurity_decrease, min_samples_leaf]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "best_acc = -1\r\n",
        "features = []\r\n",
        "\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"DecisionTreeClassifier\", \"Accuracy\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for c in criterion:\r\n",
        "        for d in max_depth:\r\n",
        "            for f in max_features:\r\n",
        "                for l in max_leaf_nodes:\r\n",
        "                    for i in min_impurity_decrease:\r\n",
        "                        for ml in min_samples_leaf:\r\n",
        "                            model = DecisionTreeClassifier(criterion=c, max_depth=d, max_features=f, max_leaf_nodes=l, min_impurity_decrease=i, min_samples_leaf=ml)\r\n",
        "                            scores = cross_val_score(model, X, y, cv=100, n_jobs=-1) # 100-fold cross-validation\r\n",
        "                            avg_accuracy = sum(scores) / len(scores) # evaluation metric\r\n",
        "\r\n",
        "                            # update best accuracy score\r\n",
        "                            if avg_accuracy > best_acc: \r\n",
        "                                best_acc = avg_accuracy\r\n",
        "                                features = [c, d, f, l, i, ml]\r\n",
        "                                print(best_acc, features)\r\n",
        "                                row = [\"DecisionTreeClassifier\", best_acc]\r\n",
        "                                row.append(features)\r\n",
        "                                csvWriter.writerow(row)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7337931034482759 ['gini', 3, 55, 2, 0, 2]\n",
            "0.7441494252873566 ['gini', 3, 55, 3, 0, 2]\n",
            "0.7527126436781613 ['gini', 3, 55, 4, 0, 2]\n",
            "0.7535172413793105 ['gini', 3, 55, 5, 0, 3]\n",
            "0.7541379310344829 ['gini', 3, 55, 6, 0, 2]\n",
            "0.7555172413793106 ['gini', 3, 55, 8, 0, 2]\n",
            "0.7564137931034487 ['gini', 3, 55, 14, 0, 2]\n",
            "0.7571379310344831 ['gini', 3, 55, 15, 0, 2]\n",
            "0.7574367816091958 ['gini', 3, 55, 15, 0, 3]\n",
            "0.7596551724137933 ['gini', 3, 55, 16, 0, 3]\n",
            "0.7674252873563222 ['gini', 3, 55, 19, 0, 3]\n",
            "0.7743218390804598 ['entropy', 4, 55, 28, 0, 2]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "source": [
        "## Hyperparameter grid\r\n",
        "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\r\n",
        "penalty = ['l1', 'l2', 'elasticnet', 'none']\r\n",
        "solver = ['saga', 'sag', 'liblinear', 'lbfgs', 'newton-cg']\r\n",
        "\r\n",
        "hyperparameters = [C, penalty, solver]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "source": [
        "## Initialize model, variables\r\n",
        "best_acc = -1\r\n",
        "features = []\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"Logistic Regression\", \"Accuracy\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for c in C:\r\n",
        "        for p in penalty:\r\n",
        "            for s in solver:\r\n",
        "                model = LogisticRegression(C=c, penalty=p, solver=s)\r\n",
        "                scores = cross_val_score(model, X, y, cv=100, n_jobs=-1) # 100-fold cross-validation\r\n",
        "                avg_accuracy = sum(scores) / len(scores) # evaluation metric\r\n",
        "\r\n",
        "                # update best accuracy score\r\n",
        "                if avg_accuracy > best_acc: \r\n",
        "                    best_acc = avg_accuracy\r\n",
        "                    features = [c, p, s]\r\n",
        "                    print(best_acc, features)\r\n",
        "                    row = [\"Logistic Regression\", best_acc]\r\n",
        "                    row.append(features)\r\n",
        "                    csvWriter.writerow(row)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7337931034482759 [0.001, 'l1', 'saga']\n",
            "0.8120459770114944 [0.001, 'none', 'saga']\n",
            "0.829977011494253 [0.001, 'none', 'sag']\n",
            "0.8357701149425288 [0.001, 'none', 'lbfgs']\n",
            "0.8833333333333333 [0.001, 'none', 'newton-cg']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13216/934207866.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                 \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 100-fold cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m                 \u001b[0mavg_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# evaluation metric\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    446\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    248\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    249\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 250\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    251\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    252\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ridge Regression"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "source": [
        "## Hyperparameter grid\r\n",
        "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 2, 4, 10]\r\n",
        "solver = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\r\n",
        "\r\n",
        "hyperparameters = [alpha, solver]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "source": [
        "## Initialize model, variables\r\n",
        "best_acc = -1\r\n",
        "features = []\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"Ridge Regression\", \"Accuracy\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for a in alpha:\r\n",
        "        for s in solver:\r\n",
        "            model = RidgeClassifier(alpha=a, solver=s)\r\n",
        "            scores = cross_val_score(model, X, y, cv=100, n_jobs=-1) # 100-fold cross-validation\r\n",
        "            avg_accuracy = sum(scores) / len(scores) # evaluation metric\r\n",
        "\r\n",
        "            # update best accuracy score\r\n",
        "            if avg_accuracy > best_acc: \r\n",
        "                best_acc = avg_accuracy\r\n",
        "                features = [a, s]\r\n",
        "                print(best_acc, features)\r\n",
        "                row = [\"Ridge Regression\", best_acc]\r\n",
        "                row.append(features)\r\n",
        "                csvWriter.writerow(row)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8796091954022991 [0.0001, 'auto']\n",
            "0.8799425287356324 [0.001, 'sparse_cg']\n",
            "0.881264367816092 [0.01, 'auto']\n",
            "0.8815977011494255 [0.01, 'sparse_cg']\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Hyperparameter grid\r\n",
        "degree = [0, 1, 2, 3, 4, 5, 6]\r\n",
        "C = [0.0001, 100]\r\n",
        "gamma = [0.0001, 0.001, 0.01, 0.1, 1, 2, 4, 10, 100]\r\n",
        "kernel = ['rbf', 'linear']\r\n",
        "\r\n",
        "hyperparameters = [degree, C, gamma, kernel]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "best_acc = -1\r\n",
        "features = []\r\n",
        "\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"SVM\", \"Accuracy\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for d in degree:\r\n",
        "        for c in C:\r\n",
        "            for g in gamma:\r\n",
        "                for k in kernel:\r\n",
        "                    model = svm.SVC(degree=d,C=c,gamma=g,kernel=k)\r\n",
        "                    scores = cross_val_score(model, X, y, cv=100, n_jobs=-1) # 100-fold cross-validation\r\n",
        "                    avg_accuracy = sum(scores) / len(scores) # evaluation metric\r\n",
        "\r\n",
        "                    # update best accuracy score\r\n",
        "                    if avg_accuracy > best_acc: \r\n",
        "                        best_acc = avg_accuracy\r\n",
        "                        features = [d, c, g, k]\r\n",
        "                        print(best_acc, features)\r\n",
        "                        row = [\"SVM\", best_acc]\r\n",
        "                        row.append(features)\r\n",
        "                        csvWriter.writerow(row)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7337931034482759 [0, 0.0001, 0.0001, 'rbf']\n",
            "0.8799770114942531 [0, 100, 0.0001, 'linear']\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "## Hyperparameter grid\r\n",
        "leaf_size = list(range(1, 10))\r\n",
        "n_neighbors = list(range(20, 40))\r\n",
        "p = [1, 2, 3]\r\n",
        "\r\n",
        "hyperparameters = [leaf_size, n_neighbors, p]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "best_acc = -1\r\n",
        "features = []\r\n",
        "\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"K-Nearest Neighbors\", \"Accuracy\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for ls in leaf_size:\r\n",
        "        for n in n_neighbors:\r\n",
        "            for p_iter in p:\r\n",
        "                model = neighbors.KNeighborsClassifier(leaf_size=ls,n_neighbors=n,p=p_iter)\r\n",
        "                scores = cross_val_score(model, X, y, cv=100, n_jobs=-1) # 100-fold cross-validation\r\n",
        "                avg_accuracy = sum(scores) / len(scores) # evaluation metric\r\n",
        "\r\n",
        "                # update best accuracy score\r\n",
        "                if avg_accuracy > best_acc: \r\n",
        "                    best_acc = avg_accuracy\r\n",
        "                    features = [ls, n, p_iter]\r\n",
        "                    print(best_acc, features)\r\n",
        "                    row = [\"K-Nearest Neighbors\", best_acc]\r\n",
        "                    row.append(features)\r\n",
        "                    csvWriter.writerow(row)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "## Hyperparameter grid\r\n",
        "var_smoothing = np.logspace(0, -9, num=100)\r\n",
        "\r\n",
        "hyperparameters = [var_smoothing]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "best_acc = -1\r\n",
        "features = []\r\n",
        "\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"Naive Bayes\", \"Accuracy\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for vs in var_smoothing:\r\n",
        "        model = GaussianNB(var_smoothing=vs)\r\n",
        "        scores = cross_val_score(model, X, y, cv=100, n_jobs=-1) # 100-fold cross-validation\r\n",
        "        avg_accuracy = sum(scores) / len(scores) # evaluation metric\r\n",
        "\r\n",
        "        # update best accuracy score\r\n",
        "        if avg_accuracy > best_acc: \r\n",
        "            best_acc = avg_accuracy\r\n",
        "            features = [vs]\r\n",
        "            print(best_acc, features)\r\n",
        "            row = [\"Naive Bayes\", best_acc]\r\n",
        "            row.append(features)\r\n",
        "            csvWriter.writerow(row)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7337931034482759 [1.0]\n"
          ]
        }
      ],
      "metadata": {}
    }
  ]
}