{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit"
    },
    "interpreter": {
      "hash": "b0931cbda49a367a3c833cb834d5f4d0941678f7c476e296a8a1c6cc66711138"
    },
    "colab": {
      "name": "statistical_learning.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lWhM2vwVucoT",
        "0DdGJqIGk7Q1",
        "1RSR72-mfd1G",
        "0VNTdnCElMS3",
        "abSy0PLGlUVI",
        "OV_dJWtplk8S",
        "GX1UFbIQlEvk",
        "zAEAJMiYoQPE",
        "Uu43P7cIobzG",
        "28Fmcm7wpW3U",
        "8NBV0GAdyEty",
        "oglO1rwJyJ2A",
        "rQQ16w6j6_4a",
        "rWQVtpQikiLB"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "lWhM2vwVucoT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "# import models\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.linear_model import Lasso\r\n",
        "from sklearn.preprocessing import PolynomialFeatures\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.linear_model import RidgeClassifier\r\n",
        "from sklearn import neighbors\r\n",
        "from sklearn import svm\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "# import other libraries\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "import csv\r\n",
        "import pandas as pd\r\n",
        "import os"
      ],
      "outputs": [],
      "metadata": {
        "id": "sj98TdfTkzID"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# load data\r\n",
        "class data_frame():\r\n",
        "    def __init__(self, folder_path):\r\n",
        "        self.X_train = pd.read_csv(os.path.join(folder_path, 'train/samples.csv')).drop('Unnamed: 0', axis=1).drop('subject', axis=1)\r\n",
        "        self.y_train = pd.read_csv(os.path.join(folder_path, 'train/labels.csv')).drop('Unnamed: 0', axis=1)\r\n",
        "        self.X_test = pd.read_csv(os.path.join(folder_path, 'test/samples.csv')).drop('Unnamed: 0', axis=1).drop('subject', axis=1)\r\n",
        "        self.y_test = pd.read_csv(os.path.join(folder_path, 'test/labels.csv')).drop('Unnamed: 0', axis=1)\r\n",
        "\r\n",
        "k=10\r\n",
        "def load_data(src):\r\n",
        "    data = []\r\n",
        "    for i in range(0, k):\r\n",
        "        data.append(data_frame(os.path.join(src, str(i))))\r\n",
        "    \r\n",
        "    return data\r\n",
        "data = load_data(\"L:\\\\Autonomic Medicine\\\\Dysmorphology Photos\\\\Facial recognition project\\\\cchs-prediction\\\\data\\\\stratify_people\\\\train\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "-GH6_POV7iTC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "data"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<__main__.data_frame at 0x2ce85ae2f70>,\n",
              " <__main__.data_frame at 0x2ce85aa9a30>,\n",
              " <__main__.data_frame at 0x2ce85afdd30>,\n",
              " <__main__.data_frame at 0x2ce84c705e0>,\n",
              " <__main__.data_frame at 0x2ce85b37c10>,\n",
              " <__main__.data_frame at 0x2ce85b37a30>,\n",
              " <__main__.data_frame at 0x2ce85b45550>,\n",
              " <__main__.data_frame at 0x2ce85b45c70>,\n",
              " <__main__.data_frame at 0x2ce85b4cc10>,\n",
              " <__main__.data_frame at 0x2ce85b4cf70>]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "source": [
        "# create csv\r\n",
        "OUTPUT_FILE = r\"L:/Autonomic Medicine/Dysmorphology Photos/Facial recognition project/cchs-prediction/data/grid-search/grid_search_results2.csv\""
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grid Search"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "## Hyperparameter grid\r\n",
        "criterion = ['gini', 'entropy']\r\n",
        "max_depth = [3, 4, 5]\r\n",
        "max_features = [55, 56]\r\n",
        "max_leaf_nodes = list(range(2, 30))\r\n",
        "min_impurity_decrease = [0, 0.1]\r\n",
        "min_samples_leaf = [2, 3]\r\n",
        "\r\n",
        "hyperparameters = [criterion, max_depth, max_features, max_leaf_nodes, min_impurity_decrease, min_samples_leaf]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "class evaluation():\r\n",
        "    def __init__(self, cnf_matrix):\r\n",
        "        self.sensitivity = self.sensitivity(cnf_matrix)\r\n",
        "        self.specificity = self.specificity(cnf_matrix)\r\n",
        "    def sensitivity(self, cnf_matrix):\r\n",
        "        tp = cnf_matrix[1][1]\r\n",
        "        fn = cnf_matrix[1][0]\r\n",
        "        return tp / (tp+fn)\r\n",
        "    def specificity(self, cnf_matrix):\r\n",
        "        tn = cnf_matrix[0][0]\r\n",
        "        fp = cnf_matrix[0][1]\r\n",
        "        return tn / (tn + fp)\r\n",
        "    def __str__(self):\r\n",
        "        return \"Sensitivity: \"+str(self.sensitivity)+\" Specificity: \"+str(self.specificity)\r\n",
        "\r\n",
        "def evaluate(cnf):\r\n",
        "    return evaluation(cnf)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "source": [
        "def k_fold_prediction(m, model_name, data):\r\n",
        "    cnf_mtx = 0 # model_name:sum(cnf_matrix) of k trials\r\n",
        "    for df in data:\r\n",
        "        m.fit(df.X_train, df.y_train.values.ravel())\r\n",
        "        y_pred = m.predict(df.X_test)\r\n",
        "        cnf_matrix = confusion_matrix(df.y_test, y_pred, labels=[0,1])\r\n",
        "\r\n",
        "        cnf_mtx += cnf_matrix\r\n",
        "    return cnf_mtx"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "import os\r\n",
        "os.getcwd()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'l:\\\\Autonomic Medicine\\\\Dysmorphology Photos\\\\Facial recognition project\\\\cchs-prediction\\\\grid-search'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "best_acc = -1\r\n",
        "features = []\r\n",
        "\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"DecisionTreeClassifier\", \"Sensitivity\", \"Specificity\", \"features\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for c in criterion:\r\n",
        "        for d in max_depth:\r\n",
        "            for f in max_features:\r\n",
        "                for l in max_leaf_nodes:\r\n",
        "                    for i in min_impurity_decrease:\r\n",
        "                        for ml in min_samples_leaf:\r\n",
        "                            model = DecisionTreeClassifier(criterion=c, max_depth=d, max_features=f, max_leaf_nodes=l, min_impurity_decrease=i, min_samples_leaf=ml)\r\n",
        "                            model_name = \"Decision Tree\"\r\n",
        "                            cnf_matrix = k_fold_prediction(model, model_name, data)\r\n",
        "                            evalu = evaluation(cnf_matrix)\r\n",
        "                            features = [c, d, f, l, i, ml]\r\n",
        "                            csvWriter.writerow([model, evalu.sensitivity, evalu.specificity, features])\r\n",
        "                            print(model, evalu.sensitivity, evalu.specificity, features)\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 2, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 2, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.14545454545454545 0.9489172681843421 ['gini', 3, 55, 3, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23471074380165288 0.9228206551915602 ['gini', 3, 55, 3, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.22975206611570248 0.9144919489172681 ['gini', 3, 55, 4, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.28760330578512394 0.9133814547473625 ['gini', 3, 55, 4, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2628099173553719 0.8989450305385897 ['gini', 3, 55, 5, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.31074380165289256 0.9028317601332593 ['gini', 3, 55, 5, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.17355371900826447 0.9372570794003331 ['gini', 3, 55, 6, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2512396694214876 0.9078289838978345 ['gini', 3, 55, 6, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2644628099173554 0.9322598556357579 ['gini', 3, 55, 7, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23140495867768596 0.9355913381454747 ['gini', 3, 55, 7, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.24297520661157024 0.9305941143808995 ['gini', 3, 55, 8, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2066115702479339 0.9089394780677401 ['gini', 3, 55, 8, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.20330578512396694 0.9294836202109938 ['gini', 3, 55, 9, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2528925619834711 0.9161576901721266 ['gini', 3, 55, 9, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.21983471074380165 0.9278178789561354 ['gini', 3, 55, 10, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2462809917355372 0.9317046085508051 ['gini', 3, 55, 10, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.22148760330578512 0.9439200444197668 ['gini', 3, 55, 11, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.32231404958677684 0.9044975013881177 ['gini', 3, 55, 11, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.21652892561983472 0.928928373126041 ['gini', 3, 55, 12, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.20330578512396694 0.928928373126041 ['gini', 3, 55, 12, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.21818181818181817 0.9278178789561354 ['gini', 3, 55, 13, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.24958677685950414 0.9217101610216546 ['gini', 3, 55, 13, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.28760330578512394 0.9033870072182121 ['gini', 3, 55, 14, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23471074380165288 0.9189339255968906 ['gini', 3, 55, 14, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.26776859504132233 0.9017212659633537 ['gini', 3, 55, 15, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2991735537190083 0.9061632426429761 ['gini', 3, 55, 15, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2396694214876033 0.926152137701277 ['gini', 3, 55, 16, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2611570247933884 0.9167129372570794 ['gini', 3, 55, 16, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.24462809917355371 0.915047196002221 ['gini', 3, 55, 17, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.22644628099173553 0.9189339255968906 ['gini', 3, 55, 17, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.19504132231404958 0.9250416435313714 ['gini', 3, 55, 18, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2049586776859504 0.9400333148250972 ['gini', 3, 55, 18, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2 0.9444752915047196 ['gini', 3, 55, 19, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.19173553719008266 0.9389228206551916 ['gini', 3, 55, 19, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.16033057851239668 0.9350360910605219 ['gini', 3, 55, 20, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3537190082644628 0.8933925596890616 ['gini', 3, 55, 20, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.21322314049586777 0.9416990560799556 ['gini', 3, 55, 21, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2066115702479339 0.9544697390338701 ['gini', 3, 55, 21, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2578512396694215 0.8972792892837312 ['gini', 3, 55, 22, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2628099173553719 0.9217101610216546 ['gini', 3, 55, 22, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2115702479338843 0.9161576901721266 ['gini', 3, 55, 23, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.25950413223140495 0.9183786785119378 ['gini', 3, 55, 23, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.17851239669421487 0.9367018323153803 ['gini', 3, 55, 24, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23636363636363636 0.9322598556357579 ['gini', 3, 55, 24, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.31735537190082647 0.917823431426985 ['gini', 3, 55, 25, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.28429752066115704 0.9144919489172681 ['gini', 3, 55, 25, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2462809917355372 0.9283731260410882 ['gini', 3, 55, 26, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.256198347107438 0.9117157134925041 ['gini', 3, 55, 26, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2066115702479339 0.9394780677401444 ['gini', 3, 55, 27, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2743801652892562 0.926152137701277 ['gini', 3, 55, 27, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2462809917355372 0.9222654081066074 ['gini', 3, 55, 28, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.30413223140495865 0.9117157134925041 ['gini', 3, 55, 28, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.17851239669421487 0.9394780677401444 ['gini', 3, 55, 29, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23140495867768596 0.9217101610216546 ['gini', 3, 55, 29, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 55, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 55, 29, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 2, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 2, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.1884297520661157 0.9244863964464186 ['gini', 3, 56, 3, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.22644628099173553 0.9133814547473625 ['gini', 3, 56, 3, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.19008264462809918 0.937812326485286 ['gini', 3, 56, 4, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2413223140495868 0.9311493614658523 ['gini', 3, 56, 4, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.27107438016528923 0.8956135480288728 ['gini', 3, 56, 5, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.29256198347107437 0.9022765130483065 ['gini', 3, 56, 5, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.22975206611570248 0.9361465852304275 ['gini', 3, 56, 6, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.16198347107438016 0.9472515269294837 ['gini', 3, 56, 6, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2115702479338843 0.928928373126041 ['gini', 3, 56, 7, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2859504132231405 0.9122709605774569 ['gini', 3, 56, 7, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2528925619834711 0.9239311493614658 ['gini', 3, 56, 8, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.22975206611570248 0.9161576901721266 ['gini', 3, 56, 8, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.26611570247933886 0.8995002776235425 ['gini', 3, 56, 9, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.18512396694214875 0.9500277623542477 ['gini', 3, 56, 9, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.20330578512396694 0.9200444197667962 ['gini', 3, 56, 10, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.24462809917355371 0.9317046085508051 ['gini', 3, 56, 10, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.21322314049586777 0.9217101610216546 ['gini', 3, 56, 11, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23801652892561984 0.9161576901721266 ['gini', 3, 56, 11, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.20330578512396694 0.926152137701277 ['gini', 3, 56, 12, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23801652892561984 0.9239311493614658 ['gini', 3, 56, 12, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.21487603305785125 0.9350360910605219 ['gini', 3, 56, 13, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.1652892561983471 0.9317046085508051 ['gini', 3, 56, 13, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.23140495867768596 0.9305941143808995 ['gini', 3, 56, 14, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.30413223140495865 0.9122709605774569 ['gini', 3, 56, 14, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.22975206611570248 0.9283731260410882 ['gini', 3, 56, 15, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2727272727272727 0.9294836202109938 ['gini', 3, 56, 15, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.21818181818181817 0.9344808439755691 ['gini', 3, 56, 16, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2727272727272727 0.9339255968906163 ['gini', 3, 56, 16, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.1884297520661157 0.9455857856746253 ['gini', 3, 56, 17, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.16033057851239668 0.9450305385896725 ['gini', 3, 56, 17, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2743801652892562 0.9328151027207107 ['gini', 3, 56, 18, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2115702479338843 0.9466962798445309 ['gini', 3, 56, 18, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2578512396694215 0.9128262076624097 ['gini', 3, 56, 19, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.20165289256198346 0.9278178789561354 ['gini', 3, 56, 19, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2413223140495868 0.9239311493614658 ['gini', 3, 56, 20, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23801652892561984 0.9056079955580233 ['gini', 3, 56, 20, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2727272727272727 0.9372570794003331 ['gini', 3, 56, 21, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2892561983471074 0.917823431426985 ['gini', 3, 56, 21, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2727272727272727 0.926152137701277 ['gini', 3, 56, 22, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.1834710743801653 0.9217101610216546 ['gini', 3, 56, 22, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.24958677685950414 0.9167129372570794 ['gini', 3, 56, 23, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23471074380165288 0.937812326485286 ['gini', 3, 56, 23, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.24793388429752067 0.9239311493614658 ['gini', 3, 56, 24, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.21983471074380165 0.9050527484730705 ['gini', 3, 56, 24, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.18181818181818182 0.9428095502498612 ['gini', 3, 56, 25, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.21818181818181817 0.9300388672959466 ['gini', 3, 56, 25, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.21322314049586777 0.9394780677401444 ['gini', 3, 56, 26, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23801652892561984 0.9200444197667962 ['gini', 3, 56, 26, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3074380165289256 0.9139367018323153 ['gini', 3, 56, 27, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2611570247933884 0.9089394780677401 ['gini', 3, 56, 27, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.23305785123966943 0.9344808439755691 ['gini', 3, 56, 28, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.27107438016528923 0.9017212659633537 ['gini', 3, 56, 28, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.27768595041322314 0.9056079955580233 ['gini', 3, 56, 29, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23140495867768596 0.9400333148250972 ['gini', 3, 56, 29, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 3, 56, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=3, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 3, 56, 29, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 2, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 2, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.24793388429752067 0.9183786785119378 ['gini', 4, 55, 3, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2231404958677686 0.9200444197667962 ['gini', 4, 55, 3, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.23636363636363636 0.920599666851749 ['gini', 4, 55, 4, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.34545454545454546 0.9072737368128817 ['gini', 4, 55, 4, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.24958677685950414 0.9244863964464186 ['gini', 4, 55, 5, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2909090909090909 0.9061632426429761 ['gini', 4, 55, 5, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2512396694214876 0.89505830094392 ['gini', 4, 55, 6, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2694214876033058 0.9117157134925041 ['gini', 4, 55, 6, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2611570247933884 0.923375902276513 ['gini', 4, 55, 7, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2462809917355372 0.9239311493614658 ['gini', 4, 55, 7, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.23305785123966943 0.9033870072182121 ['gini', 4, 55, 8, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2694214876033058 0.9317046085508051 ['gini', 4, 55, 8, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.20991735537190082 0.9367018323153803 ['gini', 4, 55, 9, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.24297520661157024 0.926152137701277 ['gini', 4, 55, 9, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.256198347107438 0.9217101610216546 ['gini', 4, 55, 10, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2793388429752066 0.9128262076624097 ['gini', 4, 55, 10, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2 0.9300388672959466 ['gini', 4, 55, 11, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.21652892561983472 0.9200444197667962 ['gini', 4, 55, 11, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.30413223140495865 0.9228206551915602 ['gini', 4, 55, 12, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2396694214876033 0.9239311493614658 ['gini', 4, 55, 12, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.24793388429752067 0.9194891726818434 ['gini', 4, 55, 13, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.31735537190082647 0.9072737368128817 ['gini', 4, 55, 13, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.20826446280991737 0.937812326485286 ['gini', 4, 55, 14, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2611570247933884 0.9267073847862298 ['gini', 4, 55, 14, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2892561983471074 0.9156024430871738 ['gini', 4, 55, 15, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.27603305785123966 0.920599666851749 ['gini', 4, 55, 15, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.32892561983471075 0.8967240421987784 ['gini', 4, 55, 16, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.18016528925619835 0.9333703498056635 ['gini', 4, 55, 16, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.33553719008264465 0.8961687951138256 ['gini', 4, 55, 17, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.27768595041322314 0.9144919489172681 ['gini', 4, 55, 17, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.24793388429752067 0.9394780677401444 ['gini', 4, 55, 18, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.21487603305785125 0.9267073847862298 ['gini', 4, 55, 18, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.24462809917355371 0.9339255968906163 ['gini', 4, 55, 19, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2809917355371901 0.9039422543031649 ['gini', 4, 55, 19, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2413223140495868 0.9222654081066074 ['gini', 4, 55, 20, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2413223140495868 0.9222654081066074 ['gini', 4, 55, 20, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2859504132231405 0.9100499722376457 ['gini', 4, 55, 21, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2528925619834711 0.9200444197667962 ['gini', 4, 55, 21, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2727272727272727 0.923375902276513 ['gini', 4, 55, 22, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3305785123966942 0.897834536368684 ['gini', 4, 55, 22, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.19834710743801653 0.9189339255968906 ['gini', 4, 55, 23, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2859504132231405 0.9194891726818434 ['gini', 4, 55, 23, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3074380165289256 0.9083842309827873 ['gini', 4, 55, 24, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2545454545454545 0.9194891726818434 ['gini', 4, 55, 24, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.23305785123966943 0.9317046085508051 ['gini', 4, 55, 25, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2793388429752066 0.9133814547473625 ['gini', 4, 55, 25, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.27768595041322314 0.9078289838978345 ['gini', 4, 55, 26, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2611570247933884 0.9117157134925041 ['gini', 4, 55, 26, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2793388429752066 0.9194891726818434 ['gini', 4, 55, 27, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3603305785123967 0.9072737368128817 ['gini', 4, 55, 27, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.31239669421487604 0.8928373126041088 ['gini', 4, 55, 28, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.28760330578512394 0.917823431426985 ['gini', 4, 55, 28, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2644628099173554 0.923375902276513 ['gini', 4, 55, 29, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2066115702479339 0.9322598556357579 ['gini', 4, 55, 29, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 55, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 55, 29, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 2, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 2, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.20165289256198346 0.9416990560799556 ['gini', 4, 56, 3, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.14214876033057852 0.9550249861188229 ['gini', 4, 56, 3, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.31239669421487604 0.9106052193225985 ['gini', 4, 56, 4, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3338842975206612 0.9128262076624097 ['gini', 4, 56, 4, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2 0.9189339255968906 ['gini', 4, 56, 5, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.30578512396694213 0.9167129372570794 ['gini', 4, 56, 5, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.28264462809917357 0.9172681843420322 ['gini', 4, 56, 6, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2694214876033058 0.9250416435313714 ['gini', 4, 56, 6, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.19008264462809918 0.9317046085508051 ['gini', 4, 56, 7, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2 0.9361465852304275 ['gini', 4, 56, 7, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.22479338842975208 0.920599666851749 ['gini', 4, 56, 8, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.27107438016528923 0.9255968906163242 ['gini', 4, 56, 8, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.20165289256198346 0.9383675735702388 ['gini', 4, 56, 9, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2628099173553719 0.9255968906163242 ['gini', 4, 56, 9, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.28760330578512394 0.9044975013881177 ['gini', 4, 56, 10, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.22644628099173553 0.926152137701277 ['gini', 4, 56, 10, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.27603305785123966 0.9189339255968906 ['gini', 4, 56, 11, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2892561983471074 0.9278178789561354 ['gini', 4, 56, 11, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.23471074380165288 0.9317046085508051 ['gini', 4, 56, 12, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2859504132231405 0.926152137701277 ['gini', 4, 56, 12, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.21322314049586777 0.915047196002221 ['gini', 4, 56, 13, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.22148760330578512 0.9344808439755691 ['gini', 4, 56, 13, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2958677685950413 0.9228206551915602 ['gini', 4, 56, 14, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.22644628099173553 0.9300388672959466 ['gini', 4, 56, 14, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2115702479338843 0.9172681843420322 ['gini', 4, 56, 15, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.34710743801652894 0.9061632426429761 ['gini', 4, 56, 15, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.25950413223140495 0.9267073847862298 ['gini', 4, 56, 16, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23471074380165288 0.9156024430871738 ['gini', 4, 56, 16, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2545454545454545 0.9161576901721266 ['gini', 4, 56, 17, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2644628099173554 0.9217101610216546 ['gini', 4, 56, 17, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.30413223140495865 0.9172681843420322 ['gini', 4, 56, 18, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.29256198347107437 0.9167129372570794 ['gini', 4, 56, 18, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2859504132231405 0.9144919489172681 ['gini', 4, 56, 19, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2909090909090909 0.9111604664075513 ['gini', 4, 56, 19, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2644628099173554 0.9017212659633537 ['gini', 4, 56, 20, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.28429752066115704 0.9228206551915602 ['gini', 4, 56, 20, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2809917355371901 0.9300388672959466 ['gini', 4, 56, 21, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2809917355371901 0.9183786785119378 ['gini', 4, 56, 21, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.20165289256198346 0.9472515269294837 ['gini', 4, 56, 22, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.21983471074380165 0.9389228206551916 ['gini', 4, 56, 22, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.30413223140495865 0.9183786785119378 ['gini', 4, 56, 23, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.22644628099173553 0.9278178789561354 ['gini', 4, 56, 23, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2809917355371901 0.9083842309827873 ['gini', 4, 56, 24, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2545454545454545 0.9194891726818434 ['gini', 4, 56, 24, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.315702479338843 0.9161576901721266 ['gini', 4, 56, 25, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.26776859504132233 0.9172681843420322 ['gini', 4, 56, 25, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.28264462809917357 0.9056079955580233 ['gini', 4, 56, 26, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.21652892561983472 0.9228206551915602 ['gini', 4, 56, 26, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.27603305785123966 0.9139367018323153 ['gini', 4, 56, 27, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.23305785123966943 0.9083842309827873 ['gini', 4, 56, 27, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3305785123966942 0.889505830094392 ['gini', 4, 56, 28, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.24462809917355371 0.9228206551915602 ['gini', 4, 56, 28, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.24297520661157024 0.9244863964464186 ['gini', 4, 56, 29, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2694214876033058 0.9161576901721266 ['gini', 4, 56, 29, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 4, 56, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=4, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 4, 56, 29, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 2, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 2, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.19834710743801653 0.9255968906163242 ['gini', 5, 55, 3, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.1206611570247934 0.9455857856746253 ['gini', 5, 55, 3, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.22975206611570248 0.9305941143808995 ['gini', 5, 55, 4, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.21487603305785125 0.9328151027207107 ['gini', 5, 55, 4, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.21983471074380165 0.9239311493614658 ['gini', 5, 55, 5, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.15702479338842976 0.94058856191005 ['gini', 5, 55, 5, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.27768595041322314 0.9250416435313714 ['gini', 5, 55, 6, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3652892561983471 0.8856191004997224 ['gini', 5, 55, 6, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.27603305785123966 0.9172681843420322 ['gini', 5, 55, 7, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3305785123966942 0.9100499722376457 ['gini', 5, 55, 7, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2628099173553719 0.8956135480288728 ['gini', 5, 55, 8, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.31239669421487604 0.8995002776235425 ['gini', 5, 55, 8, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.22148760330578512 0.9244863964464186 ['gini', 5, 55, 9, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.24462809917355371 0.9172681843420322 ['gini', 5, 55, 9, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2859504132231405 0.9117157134925041 ['gini', 5, 55, 10, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2809917355371901 0.9128262076624097 ['gini', 5, 55, 10, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3239669421487603 0.9072737368128817 ['gini', 5, 55, 11, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.30247933884297523 0.9011660188784009 ['gini', 5, 55, 11, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2115702479338843 0.9228206551915602 ['gini', 5, 55, 12, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3239669421487603 0.9017212659633537 ['gini', 5, 55, 12, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.27603305785123966 0.9189339255968906 ['gini', 5, 55, 13, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2909090909090909 0.8989450305385897 ['gini', 5, 55, 13, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.26776859504132233 0.9117157134925041 ['gini', 5, 55, 14, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.37355371900826445 0.8911715713492504 ['gini', 5, 55, 14, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3140495867768595 0.9000555247084953 ['gini', 5, 55, 15, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2793388429752066 0.9078289838978345 ['gini', 5, 55, 15, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.315702479338843 0.8906163242642976 ['gini', 5, 55, 16, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.21983471074380165 0.9217101610216546 ['gini', 5, 55, 16, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.315702479338843 0.9133814547473625 ['gini', 5, 55, 17, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.34049586776859503 0.8889505830094392 ['gini', 5, 55, 17, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3371900826446281 0.886729594669628 ['gini', 5, 55, 18, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.31074380165289256 0.8995002776235425 ['gini', 5, 55, 18, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.25950413223140495 0.9250416435313714 ['gini', 5, 55, 19, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.35206611570247937 0.8928373126041088 ['gini', 5, 55, 19, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3537190082644628 0.8756246529705719 ['gini', 5, 55, 20, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.36198347107438017 0.8911715713492504 ['gini', 5, 55, 20, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.35206611570247937 0.8967240421987784 ['gini', 5, 55, 21, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3256198347107438 0.9000555247084953 ['gini', 5, 55, 21, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.34710743801652894 0.9067184897279289 ['gini', 5, 55, 22, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3487603305785124 0.8772903942254303 ['gini', 5, 55, 22, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3140495867768595 0.9044975013881177 ['gini', 5, 55, 23, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.35206611570247937 0.8906163242642976 ['gini', 5, 55, 23, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3537190082644628 0.8856191004997224 ['gini', 5, 55, 24, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.33553719008264465 0.8889505830094392 ['gini', 5, 55, 24, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2958677685950413 0.8756246529705719 ['gini', 5, 55, 25, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.343801652892562 0.9106052193225985 ['gini', 5, 55, 25, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.39834710743801655 0.8589672404219878 ['gini', 5, 55, 26, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.371900826446281 0.883953359244864 ['gini', 5, 55, 26, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.36363636363636365 0.8945030538589672 ['gini', 5, 55, 27, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2892561983471074 0.9039422543031649 ['gini', 5, 55, 27, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3421487603305785 0.9056079955580233 ['gini', 5, 55, 28, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.33553719008264465 0.8772903942254303 ['gini', 5, 55, 28, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.35702479338842974 0.8817323709050527 ['gini', 5, 55, 29, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3504132231404959 0.897834536368684 ['gini', 5, 55, 29, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 55, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=55, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 55, 29, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 2, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 2, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=2,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.29421487603305785 0.9167129372570794 ['gini', 5, 56, 3, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.24958677685950414 0.9144919489172681 ['gini', 5, 56, 3, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=3,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3322314049586777 0.8972792892837312 ['gini', 5, 56, 4, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.21818181818181817 0.9328151027207107 ['gini', 5, 56, 4, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=4,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.24958677685950414 0.920599666851749 ['gini', 5, 56, 5, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.32892561983471075 0.8945030538589672 ['gini', 5, 56, 5, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=5,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.256198347107438 0.9255968906163242 ['gini', 5, 56, 6, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.31239669421487604 0.8817323709050527 ['gini', 5, 56, 6, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=6,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.32727272727272727 0.8911715713492504 ['gini', 5, 56, 7, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2462809917355372 0.9011660188784009 ['gini', 5, 56, 7, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=7,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.30413223140495865 0.9078289838978345 ['gini', 5, 56, 8, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2809917355371901 0.9067184897279289 ['gini', 5, 56, 8, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=8,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.30247933884297523 0.9094947251526929 ['gini', 5, 56, 9, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.27768595041322314 0.9172681843420322 ['gini', 5, 56, 9, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=9,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2909090909090909 0.9050527484730705 ['gini', 5, 56, 10, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2396694214876033 0.9167129372570794 ['gini', 5, 56, 10, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=10,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.23636363636363636 0.9372570794003331 ['gini', 5, 56, 11, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2991735537190083 0.9156024430871738 ['gini', 5, 56, 11, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=11,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.27107438016528923 0.9050527484730705 ['gini', 5, 56, 12, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.343801652892562 0.8856191004997224 ['gini', 5, 56, 12, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=12,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.32892561983471075 0.9044975013881177 ['gini', 5, 56, 13, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.256198347107438 0.9222654081066074 ['gini', 5, 56, 13, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=13,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.28760330578512394 0.9156024430871738 ['gini', 5, 56, 14, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.26611570247933886 0.9267073847862298 ['gini', 5, 56, 14, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=14,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.27603305785123966 0.9028317601332593 ['gini', 5, 56, 15, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.33884297520661155 0.8967240421987784 ['gini', 5, 56, 15, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=15,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.30247933884297523 0.9044975013881177 ['gini', 5, 56, 16, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.39173553719008264 0.8672959466962799 ['gini', 5, 56, 16, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=16,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3305785123966942 0.897834536368684 ['gini', 5, 56, 17, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3851239669421488 0.8745141588006663 ['gini', 5, 56, 17, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=17,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3768595041322314 0.8900610771793448 ['gini', 5, 56, 18, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.36363636363636365 0.8806218767351471 ['gini', 5, 56, 18, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=18,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.371900826446281 0.8961687951138256 ['gini', 5, 56, 19, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2859504132231405 0.8972792892837312 ['gini', 5, 56, 19, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=19,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2859504132231405 0.9100499722376457 ['gini', 5, 56, 20, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3504132231404959 0.8906163242642976 ['gini', 5, 56, 20, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=20,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.31239669421487604 0.8917268184342032 ['gini', 5, 56, 21, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3669421487603306 0.8883953359244864 ['gini', 5, 56, 21, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=21,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.30082644628099175 0.8995002776235425 ['gini', 5, 56, 22, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3305785123966942 0.8989450305385897 ['gini', 5, 56, 22, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=22,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.34049586776859503 0.8828428650749583 ['gini', 5, 56, 23, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.34049586776859503 0.8883953359244864 ['gini', 5, 56, 23, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=23,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3603305785123967 0.8845086063298168 ['gini', 5, 56, 24, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.34049586776859503 0.8945030538589672 ['gini', 5, 56, 24, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=24,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.35702479338842974 0.8800666296501943 ['gini', 5, 56, 25, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.34710743801652894 0.8739589117157135 ['gini', 5, 56, 25, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=25,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.35537190082644626 0.883953359244864 ['gini', 5, 56, 26, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.2859504132231405 0.8967240421987784 ['gini', 5, 56, 26, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=26,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.37355371900826445 0.8817323709050527 ['gini', 5, 56, 27, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3239669421487603 0.8911715713492504 ['gini', 5, 56, 27, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=27,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.3586776859504132 0.889505830094392 ['gini', 5, 56, 28, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.3256198347107438 0.8817323709050527 ['gini', 5, 56, 28, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=28,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=2) 0.2578512396694215 0.9017212659633537 ['gini', 5, 56, 29, 0, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0, min_samples_leaf=3) 0.29256198347107437 0.9000555247084953 ['gini', 5, 56, 29, 0, 3]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=2) 0.0 1.0 ['gini', 5, 56, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(max_depth=5, max_features=56, max_leaf_nodes=29,\n",
            "                       min_impurity_decrease=0.1, min_samples_leaf=3) 0.0 1.0 ['gini', 5, 56, 29, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 2, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 2, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.1487603305785124 0.9383675735702388 ['entropy', 3, 55, 3, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.16198347107438016 0.9411438089950028 ['entropy', 3, 55, 3, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.1537190082644628 0.9555802332037757 ['entropy', 3, 55, 4, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.15041322314049588 0.94058856191005 ['entropy', 3, 55, 4, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.26776859504132233 0.9111604664075513 ['entropy', 3, 55, 5, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.27768595041322314 0.915047196002221 ['entropy', 3, 55, 5, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.1834710743801653 0.9416990560799556 ['entropy', 3, 55, 6, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.21983471074380165 0.9317046085508051 ['entropy', 3, 55, 6, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.228099173553719 0.9372570794003331 ['entropy', 3, 55, 7, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.21322314049586777 0.9355913381454747 ['entropy', 3, 55, 7, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.18181818181818182 0.9328151027207107 ['entropy', 3, 55, 8, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2462809917355372 0.923375902276513 ['entropy', 3, 55, 8, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.23471074380165288 0.9183786785119378 ['entropy', 3, 55, 9, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.1487603305785124 0.9383675735702388 ['entropy', 3, 55, 9, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.1884297520661157 0.9500277623542477 ['entropy', 3, 55, 10, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2528925619834711 0.9039422543031649 ['entropy', 3, 55, 10, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.21818181818181817 0.926152137701277 ['entropy', 3, 55, 11, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2611570247933884 0.9194891726818434 ['entropy', 3, 55, 11, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.20165289256198346 0.9478067740144365 ['entropy', 3, 55, 12, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.18512396694214875 0.9422543031649084 ['entropy', 3, 55, 12, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.20330578512396694 0.9367018323153803 ['entropy', 3, 55, 13, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.15206611570247933 0.9444752915047196 ['entropy', 3, 55, 13, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.17851239669421487 0.9372570794003331 ['entropy', 3, 55, 14, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.21983471074380165 0.9278178789561354 ['entropy', 3, 55, 14, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.30578512396694213 0.8972792892837312 ['entropy', 3, 55, 15, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22148760330578512 0.9322598556357579 ['entropy', 3, 55, 15, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.19834710743801653 0.9428095502498612 ['entropy', 3, 55, 16, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.27107438016528923 0.9217101610216546 ['entropy', 3, 55, 16, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.1834710743801653 0.9483620210993893 ['entropy', 3, 55, 17, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.14710743801652892 0.9333703498056635 ['entropy', 3, 55, 17, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.1652892561983471 0.9283731260410882 ['entropy', 3, 55, 18, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2396694214876033 0.9311493614658523 ['entropy', 3, 55, 18, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.19504132231404958 0.9450305385896725 ['entropy', 3, 55, 19, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22479338842975208 0.9139367018323153 ['entropy', 3, 55, 19, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.18016528925619835 0.9500277623542477 ['entropy', 3, 55, 20, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.18016528925619835 0.9383675735702388 ['entropy', 3, 55, 20, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.21322314049586777 0.9328151027207107 ['entropy', 3, 55, 21, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.256198347107438 0.928928373126041 ['entropy', 3, 55, 21, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.28760330578512394 0.9161576901721266 ['entropy', 3, 55, 22, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.21983471074380165 0.9156024430871738 ['entropy', 3, 55, 22, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.22644628099173553 0.9183786785119378 ['entropy', 3, 55, 23, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.1371900826446281 0.9450305385896725 ['entropy', 3, 55, 23, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2578512396694215 0.9294836202109938 ['entropy', 3, 55, 24, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.26611570247933886 0.9228206551915602 ['entropy', 3, 55, 24, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2743801652892562 0.9244863964464186 ['entropy', 3, 55, 25, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.21487603305785125 0.9194891726818434 ['entropy', 3, 55, 25, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.21322314049586777 0.9100499722376457 ['entropy', 3, 55, 26, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2611570247933884 0.9211549139367018 ['entropy', 3, 55, 26, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2512396694214876 0.9033870072182121 ['entropy', 3, 55, 27, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.23305785123966943 0.9355913381454747 ['entropy', 3, 55, 27, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.30578512396694213 0.8956135480288728 ['entropy', 3, 55, 28, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2066115702479339 0.9305941143808995 ['entropy', 3, 55, 28, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.18677685950413223 0.9328151027207107 ['entropy', 3, 55, 29, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.19173553719008266 0.9272626318711826 ['entropy', 3, 55, 29, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 55, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 55, 29, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 2, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 2, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.10578512396694215 0.9561354802887285 ['entropy', 3, 56, 3, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.024793388429752067 0.9822320932815103 ['entropy', 3, 56, 3, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2 0.9305941143808995 ['entropy', 3, 56, 4, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.15041322314049588 0.9455857856746253 ['entropy', 3, 56, 4, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.1933884297520661 0.9250416435313714 ['entropy', 3, 56, 5, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2628099173553719 0.9083842309827873 ['entropy', 3, 56, 5, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2909090909090909 0.889505830094392 ['entropy', 3, 56, 6, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2727272727272727 0.923375902276513 ['entropy', 3, 56, 6, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.1933884297520661 0.9455857856746253 ['entropy', 3, 56, 7, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.30413223140495865 0.9028317601332593 ['entropy', 3, 56, 7, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.14710743801652892 0.9322598556357579 ['entropy', 3, 56, 8, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.25950413223140495 0.923375902276513 ['entropy', 3, 56, 8, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.1884297520661157 0.9194891726818434 ['entropy', 3, 56, 9, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.24958677685950414 0.9133814547473625 ['entropy', 3, 56, 9, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2396694214876033 0.9061632426429761 ['entropy', 3, 56, 10, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2793388429752066 0.9083842309827873 ['entropy', 3, 56, 10, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2793388429752066 0.9200444197667962 ['entropy', 3, 56, 11, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.20165289256198346 0.9156024430871738 ['entropy', 3, 56, 11, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.228099173553719 0.9466962798445309 ['entropy', 3, 56, 12, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2049586776859504 0.9300388672959466 ['entropy', 3, 56, 12, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.15537190082644628 0.9305941143808995 ['entropy', 3, 56, 13, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.32892561983471075 0.8972792892837312 ['entropy', 3, 56, 13, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.20165289256198346 0.915047196002221 ['entropy', 3, 56, 14, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.23305785123966943 0.9372570794003331 ['entropy', 3, 56, 14, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.20991735537190082 0.926152137701277 ['entropy', 3, 56, 15, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22975206611570248 0.9283731260410882 ['entropy', 3, 56, 15, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.25950413223140495 0.9061632426429761 ['entropy', 3, 56, 16, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2462809917355372 0.9044975013881177 ['entropy', 3, 56, 16, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.26611570247933886 0.9083842309827873 ['entropy', 3, 56, 17, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2231404958677686 0.9300388672959466 ['entropy', 3, 56, 17, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.228099173553719 0.9133814547473625 ['entropy', 3, 56, 18, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.1884297520661157 0.9478067740144365 ['entropy', 3, 56, 18, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.1884297520661157 0.9333703498056635 ['entropy', 3, 56, 19, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.20826446280991737 0.9411438089950028 ['entropy', 3, 56, 19, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2066115702479339 0.9372570794003331 ['entropy', 3, 56, 20, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.16859504132231404 0.94058856191005 ['entropy', 3, 56, 20, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.21983471074380165 0.928928373126041 ['entropy', 3, 56, 21, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.19173553719008266 0.9317046085508051 ['entropy', 3, 56, 21, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.15702479338842976 0.9461410327595781 ['entropy', 3, 56, 22, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.25950413223140495 0.923375902276513 ['entropy', 3, 56, 22, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2694214876033058 0.9050527484730705 ['entropy', 3, 56, 23, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2462809917355372 0.923375902276513 ['entropy', 3, 56, 23, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.23636363636363636 0.9089394780677401 ['entropy', 3, 56, 24, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.1884297520661157 0.9394780677401444 ['entropy', 3, 56, 24, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.22148760330578512 0.9156024430871738 ['entropy', 3, 56, 25, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.18016528925619835 0.9439200444197668 ['entropy', 3, 56, 25, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.25950413223140495 0.9239311493614658 ['entropy', 3, 56, 26, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2644628099173554 0.897834536368684 ['entropy', 3, 56, 26, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.17024793388429751 0.9428095502498612 ['entropy', 3, 56, 27, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.24793388429752067 0.9189339255968906 ['entropy', 3, 56, 27, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2727272727272727 0.9194891726818434 ['entropy', 3, 56, 28, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22644628099173553 0.9072737368128817 ['entropy', 3, 56, 28, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.17851239669421487 0.9355913381454747 ['entropy', 3, 56, 29, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.30578512396694213 0.8900610771793448 ['entropy', 3, 56, 29, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 3, 56, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=3, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 3, 56, 29, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 2, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 2, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.19669421487603306 0.9272626318711826 ['entropy', 4, 55, 3, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.13884297520661157 0.9539144919489173 ['entropy', 4, 55, 3, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.14214876033057852 0.9478067740144365 ['entropy', 4, 55, 4, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.20991735537190082 0.9355913381454747 ['entropy', 4, 55, 4, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2578512396694215 0.8939478067740144 ['entropy', 4, 55, 5, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.24462809917355371 0.9089394780677401 ['entropy', 4, 55, 5, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.21983471074380165 0.9250416435313714 ['entropy', 4, 55, 6, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.24793388429752067 0.9122709605774569 ['entropy', 4, 55, 6, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.23636363636363636 0.9267073847862298 ['entropy', 4, 55, 7, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2809917355371901 0.9172681843420322 ['entropy', 4, 55, 7, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.24793388429752067 0.9144919489172681 ['entropy', 4, 55, 8, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2793388429752066 0.9072737368128817 ['entropy', 4, 55, 8, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.23140495867768596 0.9172681843420322 ['entropy', 4, 55, 9, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.19173553719008266 0.9122709605774569 ['entropy', 4, 55, 9, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.171900826446281 0.9444752915047196 ['entropy', 4, 55, 10, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.1768595041322314 0.9317046085508051 ['entropy', 4, 55, 10, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.19173553719008266 0.9389228206551916 ['entropy', 4, 55, 11, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.1884297520661157 0.9311493614658523 ['entropy', 4, 55, 11, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.20826446280991737 0.915047196002221 ['entropy', 4, 55, 12, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2611570247933884 0.9228206551915602 ['entropy', 4, 55, 12, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.31239669421487604 0.9022765130483065 ['entropy', 4, 55, 13, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2396694214876033 0.9122709605774569 ['entropy', 4, 55, 13, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2644628099173554 0.9200444197667962 ['entropy', 4, 55, 14, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.23140495867768596 0.9311493614658523 ['entropy', 4, 55, 14, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2644628099173554 0.9211549139367018 ['entropy', 4, 55, 15, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.23305785123966943 0.9300388672959466 ['entropy', 4, 55, 15, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2066115702479339 0.9333703498056635 ['entropy', 4, 55, 16, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.24462809917355371 0.9139367018323153 ['entropy', 4, 55, 16, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2694214876033058 0.9139367018323153 ['entropy', 4, 55, 17, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.18677685950413223 0.923375902276513 ['entropy', 4, 55, 17, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.21487603305785125 0.9244863964464186 ['entropy', 4, 55, 18, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22148760330578512 0.9300388672959466 ['entropy', 4, 55, 18, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2049586776859504 0.9372570794003331 ['entropy', 4, 55, 19, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2512396694214876 0.9239311493614658 ['entropy', 4, 55, 19, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.20165289256198346 0.9439200444197668 ['entropy', 4, 55, 20, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.21322314049586777 0.9278178789561354 ['entropy', 4, 55, 20, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.23636363636363636 0.915047196002221 ['entropy', 4, 55, 21, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.24958677685950414 0.9344808439755691 ['entropy', 4, 55, 21, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.18677685950413223 0.9305941143808995 ['entropy', 4, 55, 22, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22644628099173553 0.9228206551915602 ['entropy', 4, 55, 22, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2578512396694215 0.920599666851749 ['entropy', 4, 55, 23, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.19173553719008266 0.9239311493614658 ['entropy', 4, 55, 23, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2743801652892562 0.926152137701277 ['entropy', 4, 55, 24, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.3074380165289256 0.9011660188784009 ['entropy', 4, 55, 24, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2528925619834711 0.9255968906163242 ['entropy', 4, 55, 25, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22148760330578512 0.9428095502498612 ['entropy', 4, 55, 25, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.17355371900826447 0.9367018323153803 ['entropy', 4, 55, 26, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.18512396694214875 0.9250416435313714 ['entropy', 4, 55, 26, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.30082644628099175 0.9183786785119378 ['entropy', 4, 55, 27, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2743801652892562 0.9111604664075513 ['entropy', 4, 55, 27, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.20991735537190082 0.9333703498056635 ['entropy', 4, 55, 28, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.24297520661157024 0.9278178789561354 ['entropy', 4, 55, 28, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.25950413223140495 0.9056079955580233 ['entropy', 4, 55, 29, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2 0.9050527484730705 ['entropy', 4, 55, 29, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 55, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 55, 29, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 2, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 2, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.13884297520661157 0.9572459744586341 ['entropy', 4, 56, 3, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.06776859504132231 0.9700166574125486 ['entropy', 4, 56, 3, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.20991735537190082 0.9139367018323153 ['entropy', 4, 56, 4, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.29256198347107437 0.9033870072182121 ['entropy', 4, 56, 4, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2975206611570248 0.9217101610216546 ['entropy', 4, 56, 5, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2892561983471074 0.889505830094392 ['entropy', 4, 56, 5, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.228099173553719 0.915047196002221 ['entropy', 4, 56, 6, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.33553719008264465 0.8845086063298168 ['entropy', 4, 56, 6, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2512396694214876 0.9111604664075513 ['entropy', 4, 56, 7, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.1884297520661157 0.9228206551915602 ['entropy', 4, 56, 7, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2512396694214876 0.9144919489172681 ['entropy', 4, 56, 8, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2231404958677686 0.9367018323153803 ['entropy', 4, 56, 8, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.21487603305785125 0.9439200444197668 ['entropy', 4, 56, 9, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.25950413223140495 0.9244863964464186 ['entropy', 4, 56, 9, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.16363636363636364 0.9305941143808995 ['entropy', 4, 56, 10, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.24793388429752067 0.9278178789561354 ['entropy', 4, 56, 10, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.19173553719008266 0.9367018323153803 ['entropy', 4, 56, 11, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.20330578512396694 0.9305941143808995 ['entropy', 4, 56, 11, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.21652892561983472 0.9500277623542477 ['entropy', 4, 56, 12, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.19834710743801653 0.937812326485286 ['entropy', 4, 56, 12, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2809917355371901 0.897834536368684 ['entropy', 4, 56, 13, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.21652892561983472 0.9144919489172681 ['entropy', 4, 56, 13, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.22479338842975208 0.9367018323153803 ['entropy', 4, 56, 14, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22479338842975208 0.9172681843420322 ['entropy', 4, 56, 14, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2413223140495868 0.915047196002221 ['entropy', 4, 56, 15, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.24958677685950414 0.9244863964464186 ['entropy', 4, 56, 15, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.15702479338842976 0.9450305385896725 ['entropy', 4, 56, 16, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.23305785123966943 0.928928373126041 ['entropy', 4, 56, 16, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2545454545454545 0.9217101610216546 ['entropy', 4, 56, 17, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.14049586776859505 0.9300388672959466 ['entropy', 4, 56, 17, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.30082644628099175 0.9089394780677401 ['entropy', 4, 56, 18, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.20826446280991737 0.9328151027207107 ['entropy', 4, 56, 18, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.15867768595041323 0.9383675735702388 ['entropy', 4, 56, 19, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22148760330578512 0.9311493614658523 ['entropy', 4, 56, 19, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2066115702479339 0.94058856191005 ['entropy', 4, 56, 20, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22479338842975208 0.9189339255968906 ['entropy', 4, 56, 20, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.15702479338842976 0.9328151027207107 ['entropy', 4, 56, 21, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.17024793388429751 0.9350360910605219 ['entropy', 4, 56, 21, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.23305785123966943 0.9283731260410882 ['entropy', 4, 56, 22, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22148760330578512 0.9350360910605219 ['entropy', 4, 56, 22, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2644628099173554 0.9250416435313714 ['entropy', 4, 56, 23, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2611570247933884 0.9317046085508051 ['entropy', 4, 56, 23, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.19173553719008266 0.9317046085508051 ['entropy', 4, 56, 24, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.18181818181818182 0.9372570794003331 ['entropy', 4, 56, 24, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2512396694214876 0.9061632426429761 ['entropy', 4, 56, 25, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22148760330578512 0.94058856191005 ['entropy', 4, 56, 25, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.228099173553719 0.9339255968906163 ['entropy', 4, 56, 26, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.21322314049586777 0.9400333148250972 ['entropy', 4, 56, 26, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2231404958677686 0.9350360910605219 ['entropy', 4, 56, 27, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2231404958677686 0.9278178789561354 ['entropy', 4, 56, 27, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2066115702479339 0.9305941143808995 ['entropy', 4, 56, 28, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.27107438016528923 0.9122709605774569 ['entropy', 4, 56, 28, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.27107438016528923 0.923375902276513 ['entropy', 4, 56, 29, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.228099173553719 0.9217101610216546 ['entropy', 4, 56, 29, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 4, 56, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=4, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 4, 56, 29, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 2, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 2, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.16033057851239668 0.9422543031649084 ['entropy', 5, 55, 3, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.1206611570247934 0.9422543031649084 ['entropy', 5, 55, 3, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.18181818181818182 0.94058856191005 ['entropy', 5, 55, 4, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.14214876033057852 0.9372570794003331 ['entropy', 5, 55, 4, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.23801652892561984 0.9200444197667962 ['entropy', 5, 55, 5, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.21652892561983472 0.9106052193225985 ['entropy', 5, 55, 5, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2892561983471074 0.9106052193225985 ['entropy', 5, 55, 6, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2958677685950413 0.9089394780677401 ['entropy', 5, 55, 6, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.30413223140495865 0.9144919489172681 ['entropy', 5, 55, 7, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.28264462809917357 0.9183786785119378 ['entropy', 5, 55, 7, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.1768595041322314 0.9283731260410882 ['entropy', 5, 55, 8, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.30247933884297523 0.9039422543031649 ['entropy', 5, 55, 8, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2975206611570248 0.8945030538589672 ['entropy', 5, 55, 9, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2909090909090909 0.9028317601332593 ['entropy', 5, 55, 9, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.3504132231404959 0.8995002776235425 ['entropy', 5, 55, 10, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.28760330578512394 0.9200444197667962 ['entropy', 5, 55, 10, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.32727272727272727 0.9028317601332593 ['entropy', 5, 55, 11, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2975206611570248 0.9161576901721266 ['entropy', 5, 55, 11, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2413223140495868 0.9156024430871738 ['entropy', 5, 55, 12, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2743801652892562 0.9039422543031649 ['entropy', 5, 55, 12, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.24462809917355371 0.9311493614658523 ['entropy', 5, 55, 13, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.26611570247933886 0.9106052193225985 ['entropy', 5, 55, 13, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.3074380165289256 0.8917268184342032 ['entropy', 5, 55, 14, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2892561983471074 0.8933925596890616 ['entropy', 5, 55, 14, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.34049586776859503 0.8928373126041088 ['entropy', 5, 55, 15, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2991735537190083 0.9039422543031649 ['entropy', 5, 55, 15, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.34545454545454546 0.8972792892837312 ['entropy', 5, 55, 16, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2975206611570248 0.9017212659633537 ['entropy', 5, 55, 16, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.315702479338843 0.8983897834536368 ['entropy', 5, 55, 17, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.31900826446280994 0.9033870072182121 ['entropy', 5, 55, 17, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2743801652892562 0.9133814547473625 ['entropy', 5, 55, 18, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.27768595041322314 0.8995002776235425 ['entropy', 5, 55, 18, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.30413223140495865 0.9122709605774569 ['entropy', 5, 55, 19, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.34049586776859503 0.8789561354802887 ['entropy', 5, 55, 19, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.3652892561983471 0.89505830094392 ['entropy', 5, 55, 20, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2975206611570248 0.9067184897279289 ['entropy', 5, 55, 20, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.3256198347107438 0.8828428650749583 ['entropy', 5, 55, 21, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.31900826446280994 0.8972792892837312 ['entropy', 5, 55, 21, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2644628099173554 0.9089394780677401 ['entropy', 5, 55, 22, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.28760330578512394 0.897834536368684 ['entropy', 5, 55, 22, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.28429752066115704 0.9039422543031649 ['entropy', 5, 55, 23, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.256198347107438 0.917823431426985 ['entropy', 5, 55, 23, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.28264462809917357 0.9061632426429761 ['entropy', 5, 55, 24, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2991735537190083 0.9139367018323153 ['entropy', 5, 55, 24, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2892561983471074 0.9022765130483065 ['entropy', 5, 55, 25, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.31735537190082647 0.9089394780677401 ['entropy', 5, 55, 25, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.31900826446280994 0.8967240421987784 ['entropy', 5, 55, 26, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2545454545454545 0.9117157134925041 ['entropy', 5, 55, 26, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2909090909090909 0.9050527484730705 ['entropy', 5, 55, 27, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.25950413223140495 0.9133814547473625 ['entropy', 5, 55, 27, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.30413223140495865 0.8861743475846752 ['entropy', 5, 55, 28, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.25950413223140495 0.9039422543031649 ['entropy', 5, 55, 28, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.27603305785123966 0.923375902276513 ['entropy', 5, 55, 29, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2644628099173554 0.9089394780677401 ['entropy', 5, 55, 29, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 55, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=55,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 55, 29, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 2, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 2, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 2, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=2, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 2, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.11570247933884298 0.9500277623542477 ['entropy', 5, 56, 3, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.06115702479338843 0.9722376457523598 ['entropy', 5, 56, 3, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 3, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=3, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 3, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2 0.9317046085508051 ['entropy', 5, 56, 4, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.24297520661157024 0.9072737368128817 ['entropy', 5, 56, 4, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 4, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=4, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 4, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.18677685950413223 0.917823431426985 ['entropy', 5, 56, 5, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.16198347107438016 0.9389228206551916 ['entropy', 5, 56, 5, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 5, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=5, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 5, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.3256198347107438 0.8939478067740144 ['entropy', 5, 56, 6, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.30082644628099175 0.9211549139367018 ['entropy', 5, 56, 6, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 6, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=6, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 6, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2958677685950413 0.8989450305385897 ['entropy', 5, 56, 7, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2231404958677686 0.9128262076624097 ['entropy', 5, 56, 7, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 7, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=7, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 7, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2396694214876033 0.9272626318711826 ['entropy', 5, 56, 8, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.30578512396694213 0.9122709605774569 ['entropy', 5, 56, 8, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 8, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=8, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 8, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2743801652892562 0.9039422543031649 ['entropy', 5, 56, 9, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.22975206611570248 0.9194891726818434 ['entropy', 5, 56, 9, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 9, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=9, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 9, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.24462809917355371 0.9133814547473625 ['entropy', 5, 56, 10, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.256198347107438 0.9272626318711826 ['entropy', 5, 56, 10, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 10, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=10, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 10, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.3322314049586777 0.9000555247084953 ['entropy', 5, 56, 11, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.21322314049586777 0.9400333148250972 ['entropy', 5, 56, 11, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 11, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=11, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 11, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2909090909090909 0.9067184897279289 ['entropy', 5, 56, 12, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.23636363636363636 0.9111604664075513 ['entropy', 5, 56, 12, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 12, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=12, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 12, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.31900826446280994 0.8956135480288728 ['entropy', 5, 56, 13, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2975206611570248 0.9228206551915602 ['entropy', 5, 56, 13, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 13, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=13, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 13, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.26611570247933886 0.9172681843420322 ['entropy', 5, 56, 14, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2545454545454545 0.9144919489172681 ['entropy', 5, 56, 14, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 14, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=14, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 14, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.34545454545454546 0.8734036646307607 ['entropy', 5, 56, 15, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.343801652892562 0.8806218767351471 ['entropy', 5, 56, 15, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 15, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=15, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 15, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.29421487603305785 0.9089394780677401 ['entropy', 5, 56, 16, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2991735537190083 0.892282065519156 ['entropy', 5, 56, 16, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 16, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=16, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 16, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2644628099173554 0.9050527484730705 ['entropy', 5, 56, 17, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.28429752066115704 0.8989450305385897 ['entropy', 5, 56, 17, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 17, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=17, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 17, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.32727272727272727 0.8961687951138256 ['entropy', 5, 56, 18, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2512396694214876 0.9217101610216546 ['entropy', 5, 56, 18, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 18, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=18, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 18, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.32231404958677684 0.8900610771793448 ['entropy', 5, 56, 19, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.3768595041322314 0.8656302054414214 ['entropy', 5, 56, 19, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 19, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=19, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 19, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.29256198347107437 0.917823431426985 ['entropy', 5, 56, 20, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2909090909090909 0.897834536368684 ['entropy', 5, 56, 20, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 20, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=20, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 20, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.22644628099173553 0.9194891726818434 ['entropy', 5, 56, 21, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.3669421487603306 0.8595224875069406 ['entropy', 5, 56, 21, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 21, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=21, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 21, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2892561983471074 0.9111604664075513 ['entropy', 5, 56, 22, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.2793388429752066 0.9033870072182121 ['entropy', 5, 56, 22, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 22, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=22, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 22, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.29421487603305785 0.8939478067740144 ['entropy', 5, 56, 23, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.27107438016528923 0.9056079955580233 ['entropy', 5, 56, 23, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 23, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=23, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 23, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.27768595041322314 0.9017212659633537 ['entropy', 5, 56, 24, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.3338842975206612 0.8872848417545808 ['entropy', 5, 56, 24, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 24, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=24, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 24, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.31074380165289256 0.9050527484730705 ['entropy', 5, 56, 25, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.315702479338843 0.8817323709050527 ['entropy', 5, 56, 25, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 25, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=25, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 25, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2793388429752066 0.9050527484730705 ['entropy', 5, 56, 26, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.32066115702479336 0.8745141588006663 ['entropy', 5, 56, 26, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 26, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=26, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 26, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.31239669421487604 0.9106052193225985 ['entropy', 5, 56, 27, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.32066115702479336 0.8989450305385897 ['entropy', 5, 56, 27, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 27, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=27, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 27, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.3338842975206612 0.8917268184342032 ['entropy', 5, 56, 28, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.3140495867768595 0.8750694058856191 ['entropy', 5, 56, 28, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 28, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=28, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 28, 0.1, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=2) 0.2859504132231405 0.9022765130483065 ['entropy', 5, 56, 29, 0, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0,\n",
            "                       min_samples_leaf=3) 0.3140495867768595 0.9072737368128817 ['entropy', 5, 56, 29, 0, 3]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=2) 0.0 1.0 ['entropy', 5, 56, 29, 0.1, 2]\n",
            "DecisionTreeClassifier(criterion='entropy', max_depth=5, max_features=56,\n",
            "                       max_leaf_nodes=29, min_impurity_decrease=0.1,\n",
            "                       min_samples_leaf=3) 0.0 1.0 ['entropy', 5, 56, 29, 0.1, 3]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "source": [
        "## Hyperparameter grid\r\n",
        "C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\r\n",
        "penalty = ['l1', 'l2', 'elasticnet', 'none']\r\n",
        "solver = ['saga', 'sag', 'liblinear', 'lbfgs', 'newton-cg']\r\n",
        "\r\n",
        "hyperparameters = [C, penalty, solver]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "source": [
        "## Initialize model, variables\r\n",
        "best_acc = -1\r\n",
        "features = []\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"Logistic Regression\", \"Sensitivity\", \"Specificity\", \"features\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for c in C:\r\n",
        "        for p in penalty:\r\n",
        "            for s in solver:\r\n",
        "                try:\r\n",
        "                    model = LogisticRegression(C=c, penalty=p, solver=s)\r\n",
        "                    model_name = \"Logistic Regression\"\r\n",
        "                    cnf_matrix = k_fold_prediction(model, model_name, data)\r\n",
        "                    evalu = evaluation(cnf_matrix)\r\n",
        "                    features = [c, d, f, l, i, ml]\r\n",
        "                    csvWriter.writerow([model, evalu.sensitivity, evalu.specificity, features])\r\n",
        "                    print(model, evalu.sensitivity, evalu.specificity, features)\r\n",
        "                except (ValueError):\r\n",
        "                    continue"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.001, penalty='l1', solver='saga') 0.0 1.0 [0.001, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.001, penalty='l1', solver='liblinear') 0.0 1.0 [0.001, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.001, solver='saga') 0.0 1.0 [0.001, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.001, solver='sag') 0.0 1.0 [0.001, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.001, solver='liblinear') 0.0 1.0 [0.001, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.001) 0.0 1.0 [0.001, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.001, solver='newton-cg') 0.0 1.0 [0.001, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.001, penalty='none', solver='saga') 0.3338842975206612 0.9583564686285397 [0.001, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.001, penalty='none', solver='sag') 0.4380165289256198 0.9455857856746253 [0.001, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.001, penalty='none') 0.5239669421487604 0.9244863964464186 [0.001, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.001, penalty='none', solver='newton-cg') 0.6859504132231405 0.9183786785119378 [0.001, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.01, penalty='l1', solver='saga') 0.0 1.0 [0.01, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.01, penalty='l1', solver='liblinear') 0.0 1.0 [0.01, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.01, solver='saga') 0.0 1.0 [0.01, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.01, solver='sag') 0.0 1.0 [0.01, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.01, solver='liblinear') 0.0 1.0 [0.01, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.01) 0.0 1.0 [0.01, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.01, solver='newton-cg') 0.0 1.0 [0.01, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.01, penalty='none', solver='saga') 0.3338842975206612 0.9583564686285397 [0.01, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.01, penalty='none', solver='sag') 0.43471074380165287 0.9461410327595781 [0.01, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.01, penalty='none') 0.5239669421487604 0.9244863964464186 [0.01, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.01, penalty='none', solver='newton-cg') 0.6859504132231405 0.9183786785119378 [0.01, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.1, penalty='l1', solver='saga') 0.0 1.0 [0.1, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.1, penalty='l1', solver='liblinear') 0.0 1.0 [0.1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.1, solver='saga') 0.0 1.0 [0.1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.1, solver='sag') 0.0 1.0 [0.1, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.1, solver='liblinear') 0.0 1.0 [0.1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.1) 0.0 1.0 [0.1, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=0.1, solver='newton-cg') 0.0 1.0 [0.1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.1, penalty='none', solver='saga') 0.3338842975206612 0.9583564686285397 [0.1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.1, penalty='none', solver='sag') 0.43636363636363634 0.9461410327595781 [0.1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.1, penalty='none') 0.5239669421487604 0.9244863964464186 [0.1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=0.1, penalty='none', solver='newton-cg') 0.6859504132231405 0.9183786785119378 [0.1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1, penalty='l1', solver='saga') 0.24462809917355371 0.9750138811771238 [1, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=1, penalty='l1', solver='liblinear') 0.371900826446281 0.9578012215435869 [1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1, solver='saga') 0.1933884297520661 0.9816768461965575 [1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1, solver='sag') 0.20165289256198346 0.9822320932815103 [1, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=1, solver='liblinear') 0.2049586776859504 0.9811215991116047 [1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1) 0.20330578512396694 0.9811215991116047 [1, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=1, solver='newton-cg') 0.2049586776859504 0.9811215991116047 [1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1, penalty='none', solver='saga') 0.33553719008264465 0.9589117157134925 [1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1, penalty='none', solver='sag') 0.43471074380165287 0.9455857856746253 [1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1, penalty='none') 0.5239669421487604 0.9244863964464186 [1, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=1, penalty='none', solver='newton-cg') 0.6859504132231405 0.9183786785119378 [1, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=10, penalty='l1', solver='saga') 0.3256198347107438 0.9616879511382566 [10, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=10, penalty='l1', solver='liblinear') 0.6082644628099173 0.9416990560799556 [10, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=10, solver='saga') 0.3140495867768595 0.963353692393115 [10, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=10, solver='sag') 0.39008264462809916 0.9555802332037757 [10, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=10, solver='liblinear') 0.4578512396694215 0.9533592448639645 [10, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=10) 0.44958677685950416 0.943364797334814 [10, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=10, solver='newton-cg') 0.45454545454545453 0.9494725152692949 [10, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=10, penalty='none', solver='saga') 0.33553719008264465 0.9583564686285397 [10, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=10, penalty='none', solver='sag') 0.43636363636363634 0.9461410327595781 [10, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=10, penalty='none') 0.5239669421487604 0.9244863964464186 [10, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=10, penalty='none', solver='newton-cg') 0.6859504132231405 0.9183786785119378 [10, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=100, penalty='l1', solver='saga') 0.3322314049586777 0.9583564686285397 [100, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=100, penalty='l1', solver='liblinear') 0.6628099173553719 0.9350360910605219 [100, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=100, solver='saga') 0.32892561983471075 0.9594669627984453 [100, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=100, solver='sag') 0.43140495867768597 0.9466962798445309 [100, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=100, solver='liblinear') 0.6066115702479339 0.9416990560799556 [100, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=100) 0.5206611570247934 0.9339255968906163 [100, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=100, solver='newton-cg') 0.6082644628099173 0.9416990560799556 [100, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=100, penalty='none', solver='saga') 0.33553719008264465 0.9583564686285397 [100, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=100, penalty='none', solver='sag') 0.43636363636363634 0.9461410327595781 [100, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=100, penalty='none') 0.5239669421487604 0.9244863964464186 [100, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=100, penalty='none', solver='newton-cg') 0.6859504132231405 0.9183786785119378 [100, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1000, penalty='l1', solver='saga') 0.3338842975206612 0.9583564686285397 [1000, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1000, penalty='l1', solver='liblinear') 0.6595041322314049 0.9344808439755691 [1000, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1000, solver='saga') 0.33553719008264465 0.9589117157134925 [1000, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1000, solver='sag') 0.43471074380165287 0.9461410327595781 [1000, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=1000, solver='liblinear') 0.6528925619834711 0.9411438089950028 [1000, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1000) 0.512396694214876 0.9283731260410882 [1000, 5, 56, 29, 0.1, 3]\n",
            "LogisticRegression(C=1000, solver='newton-cg') 0.6545454545454545 0.9411438089950028 [1000, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1000, penalty='none', solver='saga') 0.3338842975206612 0.9583564686285397 [1000, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\"The max_iter was reached which means \"\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1000, penalty='none', solver='sag') 0.43636363636363634 0.9461410327595781 [1000, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1000, penalty='none') 0.5239669421487604 0.9244863964464186 [1000, 5, 56, 29, 0.1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "C:\\Users\\anmittal\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(C=1000, penalty='none', solver='newton-cg') 0.6859504132231405 0.9183786785119378 [1000, 5, 56, 29, 0.1, 3]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ridge Regression"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "source": [
        "## Hyperparameter grid\r\n",
        "alpha = [0.0001, 0.001, 0.01, 0.1, 1, 2, 4, 10]\r\n",
        "solver = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\r\n",
        "\r\n",
        "hyperparameters = [alpha, solver]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "source": [
        "## Initialize model, variables\r\n",
        "best_acc = -1\r\n",
        "features = []\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"Ridge Regression\", \"Sensitivity\", \"Specificity\", \"features\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for a in alpha:\r\n",
        "        for s in solver:\r\n",
        "            try:\r\n",
        "                model = RidgeClassifier(alpha=a, solver=s)\r\n",
        "                model_name = \"Ridge Regression\"\r\n",
        "                cnf_matrix = k_fold_prediction(model, model_name, data)\r\n",
        "                evalu = evaluation(cnf_matrix)\r\n",
        "                features = [c, d, f, l, i, ml]\r\n",
        "                csvWriter.writerow([model, evalu.sensitivity, evalu.specificity, features])\r\n",
        "                print(model, evalu.sensitivity, evalu.specificity, features)\r\n",
        "            except (ValueError):\r\n",
        "                continue"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RidgeClassifier(alpha=0.0001) 0.6380165289256199 0.9400333148250972 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.0001, solver='svd') 0.6380165289256199 0.9400333148250972 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.0001, solver='cholesky') 0.6380165289256199 0.9400333148250972 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.0001, solver='lsqr') 0.5702479338842975 0.9444752915047196 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.0001, solver='sparse_cg') 0.6380165289256199 0.9394780677401444 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.0001, solver='sag') 0.5917355371900826 0.9561354802887285 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.0001, solver='saga') 0.5619834710743802 0.9572459744586341 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.001) 0.628099173553719 0.943364797334814 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.001, solver='svd') 0.628099173553719 0.943364797334814 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.001, solver='cholesky') 0.628099173553719 0.943364797334814 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.001, solver='lsqr') 0.5619834710743802 0.9450305385896725 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.001, solver='sparse_cg') 0.631404958677686 0.9444752915047196 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.001, solver='sag') 0.5867768595041323 0.9555802332037757 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.001, solver='saga') 0.5603305785123966 0.9566907273736813 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.01) 0.6033057851239669 0.9533592448639645 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.01, solver='svd') 0.6033057851239669 0.9533592448639645 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.01, solver='cholesky') 0.6033057851239669 0.9533592448639645 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.01, solver='lsqr') 0.5504132231404959 0.9489172681843421 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.01, solver='sparse_cg') 0.6 0.9528039977790117 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.01, solver='sag') 0.5768595041322314 0.9555802332037757 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.01, solver='saga') 0.5553719008264463 0.9578012215435869 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.1) 0.512396694214876 0.9627984453081622 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.1, solver='svd') 0.512396694214876 0.9627984453081622 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.1, solver='cholesky') 0.512396694214876 0.9627984453081622 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.1, solver='lsqr') 0.4793388429752066 0.9539144919489173 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.1, solver='sparse_cg') 0.512396694214876 0.9627984453081622 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.1, solver='sag') 0.4991735537190083 0.9611327040533038 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=0.1, solver='saga') 0.48760330578512395 0.960577456968351 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=1) 0.3239669421487603 0.9727928928373126 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=1, solver='svd') 0.3239669421487603 0.9727928928373126 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=1, solver='cholesky') 0.3239669421487603 0.9727928928373126 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=1, solver='lsqr') 0.32727272727272727 0.9722376457523598 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=1, solver='sparse_cg') 0.3256198347107438 0.9733481399222654 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=1, solver='sag') 0.32066115702479336 0.9733481399222654 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=1, solver='saga') 0.32066115702479336 0.9727928928373126 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=2) 0.2396694214876033 0.9844530816213215 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=2, solver='svd') 0.2396694214876033 0.9844530816213215 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=2, solver='cholesky') 0.2396694214876033 0.9844530816213215 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=2, solver='lsqr') 0.2413223140495868 0.9811215991116047 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=2, solver='sparse_cg') 0.2396694214876033 0.9844530816213215 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=2, solver='sag') 0.23801652892561984 0.9844530816213215 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=2, solver='saga') 0.23801652892561984 0.9855635757912271 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=4) 0.14214876033057852 0.9900055524708495 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=4, solver='svd') 0.14214876033057852 0.9900055524708495 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=4, solver='cholesky') 0.14214876033057852 0.9900055524708495 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=4, solver='lsqr') 0.14214876033057852 0.991671293725708 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=4, solver='sparse_cg') 0.14380165289256197 0.9900055524708495 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=4, solver='sag') 0.14214876033057852 0.9900055524708495 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=4, solver='saga') 0.14214876033057852 0.9900055524708495 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=10) 0.04462809917355372 0.9983342587451416 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=10, solver='svd') 0.04462809917355372 0.9983342587451416 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=10, solver='cholesky') 0.04462809917355372 0.9983342587451416 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=10, solver='lsqr') 0.04297520661157025 0.9983342587451416 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=10, solver='sparse_cg') 0.04462809917355372 0.9983342587451416 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=10, solver='sag') 0.04462809917355372 0.9983342587451416 [1000, 5, 56, 29, 0.1, 3]\n",
            "RidgeClassifier(alpha=10, solver='saga') 0.04462809917355372 0.9983342587451416 [1000, 5, 56, 29, 0.1, 3]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "source": [
        "## Hyperparameter grid\r\n",
        "degree = [0, 1, 2, 3, 4, 5, 6]\r\n",
        "C = [0.0001, 100]\r\n",
        "gamma = [0.0001, 0.001, 0.01, 0.1, 1, 2, 4, 10, 100]\r\n",
        "kernel = ['rbf', 'linear']\r\n",
        "\r\n",
        "hyperparameters = [degree, C, gamma, kernel]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "source": [
        "best_acc = -1\r\n",
        "features = []\r\n",
        "\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"SVM\", \"Sensitivity\", \"Specificity\", \"features\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for d in degree:\r\n",
        "        for c in C:\r\n",
        "            for g in gamma:\r\n",
        "                for k in kernel:\r\n",
        "                    try:\r\n",
        "                        model = svm.SVC(degree=d,C=c,gamma=g,kernel=k)\r\n",
        "                        model_name = \"SVM\"\r\n",
        "                        cnf_matrix = k_fold_prediction(model, model_name, data)\r\n",
        "                        evalu = evaluation(cnf_matrix)\r\n",
        "                        features = [c, d, f, l, i, ml]\r\n",
        "                        csvWriter.writerow([model, evalu.sensitivity, evalu.specificity, features])\r\n",
        "                        print(model, evalu.sensitivity, evalu.specificity, features)\r\n",
        "                    except (ValueError):\r\n",
        "                        continue"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC(C=0.0001, degree=0, gamma=0.0001) 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=0.0001, kernel='linear') 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=0.001) 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=0.001, kernel='linear') 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=0.01) 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=0.01, kernel='linear') 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=0.1) 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=0.1, kernel='linear') 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=1) 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=1, kernel='linear') 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=2) 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=2, kernel='linear') 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=4) 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=4, kernel='linear') 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=10) 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=10, kernel='linear') 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=100) 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=0, gamma=100, kernel='linear') 0.0 1.0 [0.0001, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=0.0001) 0.0 1.0 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=0.0001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=0.001) 0.0 1.0 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=0.001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=0.01) 0.3239669421487603 0.9683509161576902 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=0.01, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=0.1) 0.4975206611570248 0.9355913381454747 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=0.1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=1) 0.4231404958677686 0.8956135480288728 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=2) 0.3487603305785124 0.8861743475846752 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=2, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=4) 0.2743801652892562 0.8906163242642976 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=4, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=10) 0.1652892561983471 0.9211549139367018 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=10, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=100) 0.0 1.0 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=0, gamma=100, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 0, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=0.0001) 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=0.0001, kernel='linear') 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=0.001) 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=0.001, kernel='linear') 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=0.01) 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=0.01, kernel='linear') 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=0.1) 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=0.1, kernel='linear') 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=1) 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=1, kernel='linear') 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=2) 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=2, kernel='linear') 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=4) 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=4, kernel='linear') 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=10) 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=10, kernel='linear') 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=100) 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=1, gamma=100, kernel='linear') 0.0 1.0 [0.0001, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=0.0001) 0.0 1.0 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=0.0001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=0.001) 0.0 1.0 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=0.001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=0.01) 0.3239669421487603 0.9683509161576902 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=0.01, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=0.1) 0.4975206611570248 0.9355913381454747 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=0.1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=1) 0.4231404958677686 0.8956135480288728 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=2) 0.3487603305785124 0.8861743475846752 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=2, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=4) 0.2743801652892562 0.8906163242642976 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=4, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=10) 0.1652892561983471 0.9211549139367018 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=10, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=100) 0.0 1.0 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=1, gamma=100, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 1, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=0.0001) 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=0.0001, kernel='linear') 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=0.001) 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=0.001, kernel='linear') 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=0.01) 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=0.01, kernel='linear') 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=0.1) 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=0.1, kernel='linear') 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=1) 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=1, kernel='linear') 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=2) 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=2, kernel='linear') 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=4) 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=4, kernel='linear') 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=10) 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=10, kernel='linear') 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=100) 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=2, gamma=100, kernel='linear') 0.0 1.0 [0.0001, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=0.0001) 0.0 1.0 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=0.0001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=0.001) 0.0 1.0 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=0.001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=0.01) 0.3239669421487603 0.9683509161576902 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=0.01, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=0.1) 0.4975206611570248 0.9355913381454747 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=0.1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=1) 0.4231404958677686 0.8956135480288728 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=2) 0.3487603305785124 0.8861743475846752 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=2, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=4) 0.2743801652892562 0.8906163242642976 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=4, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=10) 0.1652892561983471 0.9211549139367018 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=10, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=100) 0.0 1.0 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=2, gamma=100, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 2, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=0.0001) 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=0.0001, kernel='linear') 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=0.001) 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=0.001, kernel='linear') 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=0.01) 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=0.01, kernel='linear') 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=0.1) 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=0.1, kernel='linear') 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=1) 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=1, kernel='linear') 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=2) 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=2, kernel='linear') 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=4) 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=4, kernel='linear') 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=10) 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=10, kernel='linear') 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=100) 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, gamma=100, kernel='linear') 0.0 1.0 [0.0001, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=0.0001) 0.0 1.0 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=0.0001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=0.001) 0.0 1.0 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=0.001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=0.01) 0.3239669421487603 0.9683509161576902 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=0.01, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=0.1) 0.4975206611570248 0.9355913381454747 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=0.1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=1) 0.4231404958677686 0.8956135480288728 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=2) 0.3487603305785124 0.8861743475846752 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=2, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=4) 0.2743801652892562 0.8906163242642976 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=4, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=10) 0.1652892561983471 0.9211549139367018 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=10, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=100) 0.0 1.0 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=100, gamma=100, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 3, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=0.0001) 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=0.0001, kernel='linear') 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=0.001) 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=0.001, kernel='linear') 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=0.01) 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=0.01, kernel='linear') 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=0.1) 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=0.1, kernel='linear') 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=1) 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=1, kernel='linear') 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=2) 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=2, kernel='linear') 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=4) 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=4, kernel='linear') 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=10) 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=10, kernel='linear') 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=100) 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=4, gamma=100, kernel='linear') 0.0 1.0 [0.0001, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=0.0001) 0.0 1.0 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=0.0001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=0.001) 0.0 1.0 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=0.001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=0.01) 0.3239669421487603 0.9683509161576902 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=0.01, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=0.1) 0.4975206611570248 0.9355913381454747 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=0.1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=1) 0.4231404958677686 0.8956135480288728 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=2) 0.3487603305785124 0.8861743475846752 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=2, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=4) 0.2743801652892562 0.8906163242642976 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=4, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=10) 0.1652892561983471 0.9211549139367018 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=10, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=100) 0.0 1.0 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=4, gamma=100, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 4, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=0.0001) 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=0.0001, kernel='linear') 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=0.001) 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=0.001, kernel='linear') 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=0.01) 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=0.01, kernel='linear') 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=0.1) 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=0.1, kernel='linear') 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=1) 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=1, kernel='linear') 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=2) 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=2, kernel='linear') 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=4) 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=4, kernel='linear') 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=10) 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=10, kernel='linear') 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=100) 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=5, gamma=100, kernel='linear') 0.0 1.0 [0.0001, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=0.0001) 0.0 1.0 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=0.0001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=0.001) 0.0 1.0 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=0.001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=0.01) 0.3239669421487603 0.9683509161576902 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=0.01, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=0.1) 0.4975206611570248 0.9355913381454747 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=0.1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=1) 0.4231404958677686 0.8956135480288728 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=2) 0.3487603305785124 0.8861743475846752 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=2, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=4) 0.2743801652892562 0.8906163242642976 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=4, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=10) 0.1652892561983471 0.9211549139367018 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=10, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=100) 0.0 1.0 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=5, gamma=100, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 5, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=0.0001) 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=0.0001, kernel='linear') 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=0.001) 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=0.001, kernel='linear') 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=0.01) 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=0.01, kernel='linear') 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=0.1) 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=0.1, kernel='linear') 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=1) 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=1, kernel='linear') 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=2) 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=2, kernel='linear') 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=4) 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=4, kernel='linear') 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=10) 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=10, kernel='linear') 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=100) 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=0.0001, degree=6, gamma=100, kernel='linear') 0.0 1.0 [0.0001, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=0.0001) 0.0 1.0 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=0.0001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=0.001) 0.0 1.0 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=0.001, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=0.01) 0.3239669421487603 0.9683509161576902 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=0.01, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=0.1) 0.4975206611570248 0.9355913381454747 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=0.1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=1) 0.4231404958677686 0.8956135480288728 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=1, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=2) 0.3487603305785124 0.8861743475846752 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=2, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=4) 0.2743801652892562 0.8906163242642976 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=4, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=10) 0.1652892561983471 0.9211549139367018 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=10, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=100) 0.0 1.0 [100, 6, 56, 29, 0.1, 3]\n",
            "SVC(C=100, degree=6, gamma=100, kernel='linear') 0.628099173553719 0.9428095502498612 [100, 6, 56, 29, 0.1, 3]\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "## Hyperparameter grid\r\n",
        "leaf_size = list(range(1, 10))\r\n",
        "n_neighbors = list(range(20, 40))\r\n",
        "p = [1, 2, 3]\r\n",
        "\r\n",
        "hyperparameters = [leaf_size, n_neighbors, p]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "best_acc = -1\r\n",
        "features = []\r\n",
        "\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"K-Nearest Neighbors\", \"Sensitivity\", \"Specificity\", \"features\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for ls in leaf_size:\r\n",
        "        for n in n_neighbors:\r\n",
        "            for p_iter in p:\r\n",
        "                try:\r\n",
        "                    model = neighbors.KNeighborsClassifier(leaf_size=ls,n_neighbors=n,p=p_iter)\r\n",
        "                    model_name = \"K-Nearest Neighbors\"\r\n",
        "                    cnf_matrix = k_fold_prediction(model, model_name, data)\r\n",
        "                    evalu = evaluation(cnf_matrix)\r\n",
        "                    features = [c, d, f, l, i, ml]\r\n",
        "                    csvWriter.writerow([model, evalu.sensitivity, evalu.specificity, features])\r\n",
        "                    print(model, evalu.sensitivity, evalu.specificity, features)\r\n",
        "                except (ValueError):\r\n",
        "                    continue"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Naive Bayes"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "## Hyperparameter grid\r\n",
        "var_smoothing = np.logspace(0, -9, num=100)\r\n",
        "\r\n",
        "hyperparameters = [var_smoothing]"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "best_acc = -1\r\n",
        "features = []\r\n",
        "\r\n",
        "with open(OUTPUT_FILE, \"a\", newline='') as csvfile:\r\n",
        "    csvWriter = csv.writer(csvfile)\r\n",
        "    header = [\"Naive Bayes\", \"Accuracy\"]\r\n",
        "    header.append(hyperparameters)\r\n",
        "    csvWriter.writerow(header)\r\n",
        "\r\n",
        "    for vs in var_smoothing:\r\n",
        "        model = GaussianNB(var_smoothing=vs)\r\n",
        "        scores = cross_val_score(model, X, y, cv=100, n_jobs=-1) # 100-fold cross-validation\r\n",
        "        avg_accuracy = sum(scores) / len(scores) # evaluation metric\r\n",
        "\r\n",
        "        # update best accuracy score\r\n",
        "        if avg_accuracy > best_acc: \r\n",
        "            best_acc = avg_accuracy\r\n",
        "            features = [vs]\r\n",
        "            print(best_acc, features)\r\n",
        "            row = [\"Naive Bayes\", best_acc]\r\n",
        "            row.append(features)\r\n",
        "            csvWriter.writerow(row)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7337931034482759 [1.0]\n"
          ]
        }
      ],
      "metadata": {}
    }
  ]
}